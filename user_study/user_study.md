# User study analysis

# Context

After installation and a demonstration of all the features of the extension, the 6 volunteer users were observed during a 10 minute long session interacting with IEML-RS, followed by a 15 minute interview covering each functionality and aspect: user-friendliness, usefulness, keyword navigation, translation into IEML, article search and panel comparison.   

## Results

Observations during the experiment showed that all users extracted articles from the extension, demonstrating that even for those who do not consider keyword-search as part of their research practices, the extension offered an alternative access to previously undiscovered articles. 
While they all built several requests and compared to different degrees the lists of articles, overall usefulness concerned either the building of requests from keywords and concepts navigation or the comparison of articles' lists and only one user seem equally involved in the 2 stages. All users but one corrected LLM-generated translations, and one user added comments within the grid boxes instead of erasing the LLM-translation, suggesting that when it comes to perform a semantic task, poor quality encourages a dialogic and collaborative process in which the machine automated result can act as a starting point. I would argue that translations of poor quality can be leveraged to encourage self-reflexion over the enunciation of semantically rich concepts and appropriation of the program itself. Considering that, the application's first hurdle is that very little keywords are translated, meaning that users encounter a wall of orange concepts that they  have define by themselves to fully use the application, it is an encouraging thought.

While all users suggested implementation of further functionalities and minor improvements on the UX design, most of them could be resolved by being integrated directly within the search engine interface: in-app sessions instead of reloading with each new page accessed, display of all metadata instead of only title, authors, abstract and citation count from CrossRef, clearer separation of the "requests building" stage and the "article search" stage, latency due to multiple API calls.

## Limits 

The users were 6 PhD volunteer students in DH and all knew the developper. The authors recognize that both element account for important biases in this study. 





